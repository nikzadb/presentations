{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Components-of-time-series\" data-toc-modified-id=\"Components-of-time-series-1.0.1\"><span class=\"toc-item-num\">1.0.1&nbsp;&nbsp;</span>Components of time series</a></span></li><li><span><a href=\"#Stationary\" data-toc-modified-id=\"Stationary-1.0.2\"><span class=\"toc-item-num\">1.0.2&nbsp;&nbsp;</span>Stationary</a></span></li><li><span><a href=\"#Autocorrelation-(ACF)-and-Partial-autocorrelation-(PACF)\" data-toc-modified-id=\"Autocorrelation-(ACF)-and-Partial-autocorrelation-(PACF)-1.0.3\"><span class=\"toc-item-num\">1.0.3&nbsp;&nbsp;</span>Autocorrelation (ACF) and Partial autocorrelation (PACF)</a></span></li></ul></li></ul></li><li><span><a href=\"#What-is-time-series-forecasting\" data-toc-modified-id=\"What-is-time-series-forecasting-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>What is time series forecasting</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#dataset\" data-toc-modified-id=\"dataset-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>dataset</a></span></li><li><span><a href=\"#Common-timeseries-analayis\" data-toc-modified-id=\"Common-timeseries-analayis-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Common timeseries analayis</a></span><ul class=\"toc-item\"><li><span><a href=\"#Check-Stationary\" data-toc-modified-id=\"Check-Stationary-3.2.1\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Check Stationary</a></span><ul class=\"toc-item\"><li><span><a href=\"#Decomposition\" data-toc-modified-id=\"Decomposition-3.2.1.1\"><span class=\"toc-item-num\">3.2.1.1&nbsp;&nbsp;</span>Decomposition</a></span></li><li><span><a href=\"#Dickey-Fuller-test\" data-toc-modified-id=\"Dickey-Fuller-test-3.2.1.2\"><span class=\"toc-item-num\">3.2.1.2&nbsp;&nbsp;</span>Dickey-Fuller test</a></span></li></ul></li><li><span><a href=\"#Stationarize-data\" data-toc-modified-id=\"Stationarize-data-3.2.2\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Stationarize data</a></span><ul class=\"toc-item\"><li><span><a href=\"#remove-trend\" data-toc-modified-id=\"remove-trend-3.2.2.1\"><span class=\"toc-item-num\">3.2.2.1&nbsp;&nbsp;</span>remove trend</a></span></li><li><span><a href=\"#remove-seasonality\" data-toc-modified-id=\"remove-seasonality-3.2.2.2\"><span class=\"toc-item-num\">3.2.2.2&nbsp;&nbsp;</span>remove seasonality</a></span></li></ul></li><li><span><a href=\"#Plot-ACF/PACF-to-find-optimial-parameters-(i.e.,-lags)\" data-toc-modified-id=\"Plot-ACF/PACF-to-find-optimial-parameters-(i.e.,-lags)-3.2.3\"><span class=\"toc-item-num\">3.2.3&nbsp;&nbsp;</span>Plot ACF/PACF to find optimial parameters (i.e., lags)</a></span></li></ul></li></ul></li><li><span><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Traditional-Statistical-methods\" data-toc-modified-id=\"Traditional-Statistical-methods-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Traditional Statistical methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Naive-model\" data-toc-modified-id=\"Naive-model-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Naive model</a></span></li><li><span><a href=\"#Exponential-Smoothing\" data-toc-modified-id=\"Exponential-Smoothing-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Exponential Smoothing</a></span><ul class=\"toc-item\"><li><span><a href=\"#ARIMA-(and-its-family)\" data-toc-modified-id=\"ARIMA-(and-its-family)-4.1.2.1\"><span class=\"toc-item-num\">4.1.2.1&nbsp;&nbsp;</span>ARIMA (and its family)</a></span></li><li><span><a href=\"#FB-Prophet\" data-toc-modified-id=\"FB-Prophet-4.1.2.2\"><span class=\"toc-item-num\">4.1.2.2&nbsp;&nbsp;</span>FB Prophet</a></span></li></ul></li><li><span><a href=\"#Problems-with-Traditional-Time-Series-Forecasting\" data-toc-modified-id=\"Problems-with-Traditional-Time-Series-Forecasting-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Problems with Traditional Time Series Forecasting</a></span></li></ul></li><li><span><a href=\"#Machine-learning-based-methods\" data-toc-modified-id=\"Machine-learning-based-methods-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Machine-learning based methods</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deep-neural-network\" data-toc-modified-id=\"Deep-neural-network-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>Deep neural network</a></span><ul class=\"toc-item\"><li><span><a href=\"#RNN-(LSTM,-GRU)\" data-toc-modified-id=\"RNN-(LSTM,-GRU)-4.2.1.1\"><span class=\"toc-item-num\">4.2.1.1&nbsp;&nbsp;</span>RNN (LSTM, GRU)</a></span></li><li><span><a href=\"#CNN-on-1D-data\" data-toc-modified-id=\"CNN-on-1D-data-4.2.1.2\"><span class=\"toc-item-num\">4.2.1.2&nbsp;&nbsp;</span>CNN on 1D data</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Residual-analysis\" data-toc-modified-id=\"Residual-analysis-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Residual analysis</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Appendix\" data-toc-modified-id=\"Appendix-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Appendix</a></span><ul class=\"toc-item\"><li><span><a href=\"#long-term-forecasts\" data-toc-modified-id=\"long-term-forecasts-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>long-term forecasts</a></span><ul class=\"toc-item\"><li><span><a href=\"#one-step-ahead-forecasting\" data-toc-modified-id=\"one-step-ahead-forecasting-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>one-step ahead forecasting</a></span></li><li><span><a href=\"#direct-H-step-ahead-forecasting\" data-toc-modified-id=\"direct-H-step-ahead-forecasting-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>direct H-step ahead forecasting</a></span></li><li><span><a href=\"#multiple-input-multiple-output-models\" data-toc-modified-id=\"multiple-input-multiple-output-models-7.1.3\"><span class=\"toc-item-num\">7.1.3&nbsp;&nbsp;</span>multiple input multiple output models</a></span></li></ul></li><li><span><a href=\"#Forecasting-types\" data-toc-modified-id=\"Forecasting-types-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Forecasting types</a></span><ul class=\"toc-item\"><li><span><a href=\"#Univariate\" data-toc-modified-id=\"Univariate-7.2.1\"><span class=\"toc-item-num\">7.2.1&nbsp;&nbsp;</span>Univariate</a></span></li><li><span><a href=\"#Multi-variate\" data-toc-modified-id=\"Multi-variate-7.2.2\"><span class=\"toc-item-num\">7.2.2&nbsp;&nbsp;</span>Multi-variate</a></span></li></ul></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to provide a summary of forecasting methods from statistical  to machine-learning based methods. \n",
    "\n",
    "# Introduction\n",
    "\n",
    "A time series is a <b>sequence of observations</b> that is ordered in time:\n",
    "$$ \n",
    "   (s_{t-N}, s_{t-N-1}, ..., s_{t-1}, s_{t}) \n",
    "$$\n",
    "\n",
    "Examples are: \n",
    "- Weather variables (temperature, pressure, wind)\n",
    "\n",
    "<img src='images/Air-Pollution-Time-Series.png'>\n",
    "\n",
    "- Economy and finance (GDP, indexes, exchanges)\n",
    "\n",
    "<img src='images/apple-stock.png'>\n",
    "\n",
    "- Medical (EEG, blood pressure)\n",
    "\n",
    "and many more ...\n",
    "\n",
    "\n",
    "### Components of time series\n",
    "\n",
    "A time series consists of three major companents:\n",
    "\n",
    "- base line\n",
    "- trend\n",
    "- seasonality (e.g., cyclic)\n",
    "\n",
    "<img src='images/time_series_components.png'>\n",
    "\n",
    "### Stationary\n",
    "\n",
    "A time series is called stationary if\n",
    "- Its mean is not a function of time (a result of trend in data)\n",
    "\n",
    "<img src='images/Mean_nonstationary.png'>\n",
    "\n",
    "- Its variance is not be a function of time\n",
    "\n",
    "<img src='images/Var_nonstationary.png'>\n",
    "\n",
    "- The covariance of the $i^{th}$ and $(i + m)^{th}$ terms is not be a function of time (a result of seasonality and cyclic patterns)\n",
    "\n",
    "<img src='images/Cov_nonstationary.png'>\n",
    "\n",
    "So, as the first step it is required to stationerize time series data. The reason is that:\n",
    "most of statistical and ML algorithms are based on samples independence which is not in time series observation. It is proved that most of properties for independent random variables (law of large numbers and central limit theorem to name a couple) hold for stationary random variables. So by making the data stationary, we can actually apply regression techniques to this time dependent variable.\n",
    "\n",
    "\n",
    "### Autocorrelation (ACF) and Partial autocorrelation (PACF)\n",
    "\n",
    "Samples of time series data are not i.i.d; in another word, there is dependeny beween a sample at time $t$ with the previous samples. Therefore, the previous samples can be used as informative features to predict the value of the next sample. Autocorrelation (ACF) and Partial autocorrelation (PACF) are two statistical analysis to check how many of the previous samples (a.k.a lags) have impact on the next sample.\n",
    "\n",
    "- <b>ACF</b>: shows the dependency between $t$ and previous times $(t-1, t-2, ..., t-N)$ independent from each other\n",
    "- <b>PACF</b>: shows the dependency between $t$ and previous times $(t-1, t-2, ..., t-N)$ when previous times are factored out. So, PACF between $t$ and $t-2$ is calculated after removing dependeny between $t$ and $t-1$.\n",
    "\n",
    "\n",
    "# What is time series forecasting\n",
    "\n",
    "Time series forecasting is the process of modelling a time series pattern in order to predict the feature values:\n",
    "$$ \n",
    "   (s_{t-N}, s_{t-N-1}, ..., s_{t-1}, s_{t}) -> (\\hat{s_{t+1}}, \\hat{s_{t+2}}, ..., \\hat{s_{t+K}})\n",
    "$$\n",
    "\n",
    "where\n",
    "- $s_{t-i}$ are historical observation and are available at time of forecasting.\n",
    "- $s_{t+i}$ are predictions and are not available at time of forecasting.\n",
    "\n",
    "\n",
    "Example are predicting \n",
    "- tommorow weather temperature based on previous readings\n",
    "- prediction of stock values based on their historical data !!! \n",
    "\n",
    "and so on.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "## dataset\n",
    "For this presenation, we use time series data kaggle competition: <a href='https://www.kaggle.com/andreazzini/international-airline-passengers'>International airline passengers</a>. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:42.052266Z",
     "start_time": "2020-04-21T06:19:41.264764Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from warnings import filterwarnings\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "filterwarnings(\"ignore\") \n",
    "\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y-%m')\n",
    "\n",
    "data = pd.read_csv('data/international-airline-passengers.csv', sep=',', date_parser=parser)\n",
    "data.rename(columns={\n",
    "    'Month': 'date',\n",
    "    'International airline passengers: monthly totals in thousands. Jan 49 ? Dec 60': 'num_passengers'\n",
    "}, inplace=True)\n",
    "data.sort_index(inplace=True)\n",
    "data['date'] = pd.to_datetime(data.date, infer_datetime_format=True)\n",
    "data.set_index('date', inplace=True)\n",
    "\n",
    "plt.plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common timeseries analayis\n",
    "\n",
    "### Check Stationary\n",
    "\n",
    "As mentioned before, a time series must be stationary to be used in most of statistical and ML algorithms. There are two ways to check if a time series is stationary or not:\n",
    "\n",
    "#### Decomposition\n",
    "\n",
    "By decomposition of a time series to its main components it is possible to see baseline, trend and seasonality:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:43.362159Z",
     "start_time": "2020-04-21T06:19:42.054814Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "# `additive` means decompose the time series into Error + Trend + Seasonal\n",
    "# `multiplicative` means decompose the time series into Error * Trend * Seasonal\n",
    "decomposition = seasonal_decompose(data.num_passengers,\n",
    "                            model='additive')  # model='multiplicative'\n",
    "\n",
    "plt.figure()  \n",
    "decomposition.plot()  \n",
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal \n",
    "residual = decomposition.resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dickey-Fuller test\n",
    "\n",
    "Dickey-Fuller test can be used to test stationary of data. If the Test Statistics is smaller than the Critical Value then the time series is stationary. Another way is that to say if p-value < 0.05, then the null hypothesis of non-stationary is rejected; thus, the time series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:43.439537Z",
     "start_time": "2020-04-21T06:19:43.365435Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationary(timeseries):\n",
    "    print('Results of Dickey-Fuller Test:\\n')\n",
    "    dftest = adfuller(timeseries.dropna(), autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[:4], index=['Test Statistics', 'p-value', '#lags Used', '# observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "test_stationary(data.num_passengers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarize data\n",
    "\n",
    "#### remove trend\n",
    "\n",
    "There are a few ways to remove trends:\n",
    "- <b>Log transform</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:44.337426Z",
     "start_time": "2020-04-21T06:19:43.443053Z"
    }
   },
   "outputs": [],
   "source": [
    "data['log_data'] = pd.np.log(data.num_passengers)\n",
    "\n",
    "# Apply Dickey-Fuller Test of the first difference\n",
    "test_stationary(data.log_data)\n",
    "\n",
    "# Decomposition plot\n",
    "decomposition_log = seasonal_decompose(data.log_data.dropna(), model='additive')\n",
    "_ = decomposition_log.plot()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Differencing</b>: the difference between data with its first shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:45.172783Z",
     "start_time": "2020-04-21T06:19:44.339932Z"
    }
   },
   "outputs": [],
   "source": [
    "data['first_diff'] = data.num_passengers - data.num_passengers.shift(1)\n",
    "\n",
    "# Apply Dickey-Fuller Test of the first difference\n",
    "test_stationary(data.first_diff)\n",
    "\n",
    "# Decomposition plot\n",
    "decomposition_first_diff = seasonal_decompose(data.first_diff.dropna(), model='additive')\n",
    "_ = decomposition_first_diff.plot()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Second Difference</b>: difference between first_diff with its shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:46.097408Z",
     "start_time": "2020-04-21T06:19:45.174775Z"
    }
   },
   "outputs": [],
   "source": [
    "data['second_diff'] = data.first_diff - data.first_diff.shift(1)\n",
    "\n",
    "# Apply Dickey-Fuller Test of the first difference\n",
    "test_stationary(data.second_diff)\n",
    "\n",
    "# Decomposition plot\n",
    "decomposition_second_diff = seasonal_decompose(data.second_diff.dropna(), model='additive')\n",
    "_ = decomposition_second_diff.plot()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### remove seasonality\n",
    "\n",
    "- <b>Seasonal Difference</b>: the difference between data with its seasonality (it may be monthy/yearly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:47.872405Z",
     "start_time": "2020-04-21T06:19:46.100378Z"
    }
   },
   "outputs": [],
   "source": [
    "data['seasonal_diff'] = data.num_passengers - data.num_passengers.shift(12)\n",
    "\n",
    "# Apply Dickey-Fuller Test of the first difference\n",
    "test_stationary(data.seasonal_diff)\n",
    "\n",
    "# Decomposition plot\n",
    "decomposition_seasonal_diff = seasonal_decompose(data.seasonal_diff.dropna(), model='additive')\n",
    "_ = decomposition_seasonal_diff.plot()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ACF/PACF to find optimial parameters (i.e., lags)\n",
    "\n",
    "After stationering data, ACF/PACF is used to deterime number of lags (as featues to the algorithm)\n",
    "\n",
    "- <b>ACF/PACF on first diff</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:48.502762Z",
     "start_time": "2020-04-21T06:19:47.876275Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# ACF/PACF for first diff\n",
    "figsize=(12, 4)\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "plt.subplot(121)\n",
    "_ = plot_acf(x=data.first_diff.dropna(), ax=plt.gca(), lags=30)\n",
    "plt.subplot(122)\n",
    "_ = plot_pacf(x=data.first_diff.dropna(), ax=plt.gca(), lags=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the PACF, we can conclude that lags $t-1, t-2, t-3, t-5, t-7, t-9, t-10, t-11, t-12, t-14, t-20, t-29, t-30$ have impact on sample $t$ and must be used as predective features in any statistical/ML modelling.\n",
    "\n",
    "- <b>ACF/PACF on first seasonal difference</b>\n",
    "\n",
    "As can be seen from the next PACF graph, lags $t-1, t-2, t-3, t-10, t-21, t-23$ have impact of sample $t$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:48.942302Z",
     "start_time": "2020-04-21T06:19:48.505313Z"
    }
   },
   "outputs": [],
   "source": [
    "# ACF/PACF for original data\n",
    "plt.figure(figsize=figsize)\n",
    "\n",
    "plt.subplot(121)\n",
    "_ = plot_acf(x=data.seasonal_diff.dropna(), ax=plt.gca(), lags=30)\n",
    "\n",
    "plt.subplot(122)\n",
    "_ = plot_pacf(x=data.seasonal_diff.dropna(), ax=plt.gca(), lags=30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "It should be noted that the time series must be stationerized before any modelling. ARIMA family and Prophet have an internal mechanism to stationerize data.\n",
    "\n",
    "## Traditional Statistical methods\n",
    "\n",
    "\n",
    "### Naive model\n",
    "\n",
    "The naive model is based on the assumption that value of sample $t$ is close to similar previous occausions:\n",
    "- The number of passengers is Feb can be calculated as the average of the number of passengers in previous years at the same month\n",
    "- The number of sales on an item on the next week can be calculated as the average of the item sales in the same weeks last years OR same weeks in previous months\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:48.960285Z",
     "start_time": "2020-04-21T06:19:48.945388Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:48.967040Z",
     "start_time": "2020-04-21T06:19:48.962754Z"
    }
   },
   "outputs": [],
   "source": [
    "def naive_model(data, period=12):\n",
    "    \n",
    "    return data\n",
    "\n",
    "pred_naive_model = naive_model(data=data['first_diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Smoothing\n",
    "\n",
    "\n",
    "- <b>Simple Exponential Smoothing (SES)</b>: SES is a good choice for forecasting data with no clear trend or seasonal pattern. Forecasts are calculated using weighted averages, which means the largest weights are associated with most recent observations, while the smallest weights are associated with the oldest observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:21:18.113935Z",
     "start_time": "2020-04-21T06:21:17.863901Z"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import SimpleExpSmoothing\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "data.seasonal_diff.dropna().plot(marker='o', label=\"Actual\")\n",
    "\n",
    "_fit = SimpleExpSmoothing(data.seasonal_diff.dropna()).fit()\n",
    "_fcast = _fit.forecast(30).rename(\"Simple Exponential Smoothing\")\n",
    "_fit.fittedvalues.plot(style='--',  color='green')\n",
    "\n",
    "_fcast.plot(marker='o', color='green', legend=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>(Holt Winter's) Exponential Smoothing:</b> Holt-Winters’ Method is suitable for data with trends and seasonalities which includes a seasonality smoothing parameter $\\gamma$. There are two variations to this method:\n",
    "    - <b>Additive method:</b> the seasonal variations are roughly constant through the series.\n",
    "    - <b>Multiplicative method:</b> the seasonal variations are changing proportionally to the level of the series.\n",
    "    \n",
    "In following we run the Holt Winter algorithm with a combination of Adetive/Multiplicatiove for trend and season    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:21:27.029188Z",
     "start_time": "2020-04-21T06:21:26.721682Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "\n",
    "params = [\n",
    "    {\n",
    "        'trend': 'add', 'seasonal': 'add', 'seasonal_periods': 12\n",
    "    },\n",
    "    {\n",
    "        'trend': 'add', 'seasonal': 'mul', 'seasonal_periods': 12\n",
    "    },\n",
    "    {\n",
    "        'trend': 'mul', 'seasonal': 'add', 'seasonal_periods': 12\n",
    "    },\n",
    "    {\n",
    "        'trend': 'mul', 'seasonal': 'mul', 'seasonal_periods': 12\n",
    "    }\n",
    "]\n",
    "\n",
    "colors = [\n",
    "    {\n",
    "        'style': '--', 'color': 'blue'\n",
    "    },\n",
    "    {\n",
    "        'style': '--', 'color': 'green'\n",
    "    },\n",
    "    {\n",
    "        'style': '--', 'color': 'red'\n",
    "    },\n",
    "    {\n",
    "        'style': '--', 'color': 'yellow'\n",
    "    }    \n",
    "]\n",
    "\n",
    "plt.figure(figsize=figsize)\n",
    "data.num_passengers.plot(label=\"Actual\", marker='o')\n",
    "\n",
    "for color, param in zip(colors, params):    \n",
    "    _fit = ExponentialSmoothing(data.num_passengers, **param).fit(use_boxcox=True)\n",
    "    _fcast = _fit.forecast(30).rename(f\"{param}\")\n",
    "    _fit.fittedvalues.plot(**color)\n",
    "    \n",
    "    _fcast.plot(**color, legend=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA (and its family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FB Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-21T06:19:52.123608Z",
     "start_time": "2020-04-21T06:19:50.411702Z"
    }
   },
   "outputs": [],
   "source": [
    "import fbprophet as prophet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems with Traditional Time Series Forecasting\n",
    "\n",
    "- They require complete data. Some missing values can really affect the models. But there are also ways to deal with missing data, as I found a great discussion on that topic: https://gking.harvard.edu/files/pr.pdf.\n",
    "- They rely on linear relationships. In many traditional models, their assumptions are linearly based but not complex joint distribution based.\n",
    "- They usually only deal with univariate data. In real world, we can see many dataset have multiple inputs. For instance, if we want to predict the air pressure in one area, it’s also helpful investigate the air pressures in other areas because they might have a potential effect on the given area.\n",
    "- They usually don’t work well in long term forecast. Probably only useful in one-step forecast.\n",
    "\n",
    "## Machine-learning based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep neural network\n",
    "\n",
    "#### RNN (LSTM, GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CNN on 1D data\n",
    "\n",
    "Convolutional Neural Networks(CNN) is often used in image classifications and had amazing results in the past. They have promises in computer vision problems like object localization, object classifications, image captioning and etc. They broke down images into pixels instead of handcrafting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residual analysis\n",
    "\n",
    "Residual analysis is a common method to see the goodness of a modelling. However, there are a few more residual analysis in time series\n",
    "\n",
    "- <b>Check ACF and PACF of residuals</b>: there must not be dependency between a sample in residual and its lags; in another word, residuals are i.i.d\n",
    "\n",
    "- <b>Check normality of residuals using Q-Q plot</b>: the residual must be normaly distributed (similar to noise); bascilly, it is expected the error be normal around zero. Lower vriance means better model. To check the normality of data (or errer), use normaltest() in SciPy How to Use Statistical Significance Tests to Interpret Machine Learning Results\n",
    "\n",
    "- <b>Test for stationarity using Dickey-Fuller Test</b>: the residual must be stationary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "## long-term forecasts\n",
    "\n",
    "### one-step ahead forecasting\n",
    "\n",
    "\n",
    "### direct H-step ahead forecasting\n",
    "\n",
    "\n",
    "### multiple input multiple output models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Forecasting types\n",
    "\n",
    "### Univariate\n",
    "\n",
    "\n",
    "### Multi-variate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- <a href='https://medium.com/datadriveninvestor/how-to-build-exponential-smoothing-models-using-python-simple-exponential-smoothing-holt-and-da371189e1a1'>How to Build Exponential Smoothing Models Using Python: Simple Exponential Smoothing, Holt, and Holt-Winters</a>\n",
    "\n",
    "- <a href='https://thuijskens.github.io/2016/08/03/time-series-forecasting/'>Long-term forecasting with machine learning models</a>\n",
    "\n",
    "- <a href='http://www.seanabu.com/2016/03/22/time-series-seasonal-ARIMA-model-in-python/'>Seasonal ARIMA with Python</a>\n",
    "\n",
    "- <a href='https://www.kaggle.com/moizzz/introduction-to-forecasting'>Introduction to Forecasting</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
